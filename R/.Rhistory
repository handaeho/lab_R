# 모든 변수들이 정규화 된 데이터 프레임으로 변환
# 현재 wbcd의 첫 번쨰 컬럼은 '진단 결과' 이므로 정규화에서는 제외
str(wbcd)
str(iris)
# 정규화
normalize = function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# 마지막 4번째 컬럼은 '종'이므로 정규화에서 제거
iris_n = as.data.frame(lapply(iris[1:3], normalize))
#결과 확인
summary(iris_n)
iris_train = sample(1:nrow(iris_n), 100) # '학습(훈련) 데이터 세트(100개 관찰 값)'
iris_train
iris_n
iris_train
iris_test = sample(1:nrow(iris_n),50) # '테스트 데이터 세트(50개 관찰 값)'
iris_test
iris_test
# 정답지 만들기
iris_train_label = wbcd[1:100, 4] # 학습 데이터 정답지
table(iris_train_label)
prop.table(table(iris_train_label))
prop.table(table(iris_train_label))
table(iris_train_label)
# 정답지 만들기
iris_train_label = wbcd[1:100, 6] # 학습 데이터 정답지
table(iris_train_label)
# 정답지 만들기
iris_train_label = wbcd[1:100, 5] # 학습 데이터 정답지
table(iris_train_label)
# 정답지 만들기
iris_train_label = iris[1:100, 6] # 학습 데이터 정답지
table(iris_train_label)
# 정답지 만들기
iris_train_label = iris[1:100, 5] # 학습 데이터 정답지
table(iris_train_label)
# 정답지 만들기
iris_train_label = iris[1:100, 4] # 학습 데이터 정답지
table(iris_train_label)
iris_n
iris
# 데이터 프레임의 필요없는 첫 번째 컬럼인 id 제거
iris = iris[-1]
iris
rm(list=ls())
# 실습) iris 종 판별하기 ===================================================================================
iris = read.csv("data/Iris.csv")
str(iris)
# 데이터 프레임의 필요없는 첫 번째 컬럼인 id 제거
iris = iris[-1]
str(iris)
# 재현성 위한 seed설정
set.seed(123)
rm(list=ls())
# 실습) iris 종 판별하기 ===================================================================================
iris = read.csv("data/Iris.csv")
str(iris)
# 실습) iris 종 판별하기 ===================================================================================
iris = read.csv("data/Iris.csv")
str(iris)
# 데이터 프레임의 필요없는 첫 번째 컬럼인 id 제거
iris = iris[-1]
str(iris)
# 각 species 수 & 비율 확인
table(iris$Species)
prop.table(table(iris$Species))
# 정규화
normalize = function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# 마지막 4번째 컬럼은 '종'이므로 정규화에서 제거
iris_n = as.data.frame(lapply(iris[1:3], normalize))
summary(iris_n)
# 랜덤 위한 시드값 생성
set.seed(1234)
iris_train = sample(2:nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25)) # '학습(훈련) 데이터 세트(100개 관찰 값)'
iris_train = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25)) # '학습(훈련) 데이터 세트(100개 관찰 값)'
rm(list=ls())
# 실습) iris 종 판별하기 ===================================================================================
iris = read.csv("data/Iris.csv")
str(iris)
# 데이터 프레임의 필요없는 첫 번째 컬럼인 id 제거
iris = iris[-1]
str(iris)
# 각 species 수 & 비율 확인
table(iris$Species)
prop.table(table(iris$Species))
# 정규화
normalize = function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# 마지막 4번째 컬럼은 '종'이므로 정규화에서 제거
iris_n = as.data.frame(lapply(iris[1:3], normalize))
summary(iris_n)
# 랜덤 위한 시드값 생성
set.seed(1234)
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25)) # '학습(훈련) 데이터 세트(100개 관찰 값)'
# 학습(훈련) 데이터 세트
iris_train = iris(random_sample == 1, 1:4)
# 학습(훈련) 데이터 세트
iris_train = iris_n(random_sample == 1, 1:4)
# 실습) iris 종 판별하기 ===================================================================================
iris = read.csv("data/Iris.csv")
str(iris)
# 데이터 프레임의 필요없는 첫 번째 컬럼인 id 제거
iris = iris[-1]
str(iris)
# 각 species 수 & 비율 확인
table(iris$Species)
prop.table(table(iris$Species))
# 정규화
normalize = function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# 마지막 4번째 컬럼은 '종'이므로 정규화에서 제거
iris_n = as.data.frame(lapply(iris[1:3], normalize))
#결과 확인
summary(iris_n)
iris_n
# 랜덤 위한 시드값 생성
set.seed(1234)
# 75 : 25의 비율로 데이터 나눔
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25))
# 학습(훈련) 데이터 세트
iris_train = iris_n(random_sample == 1, 1:4)
# 학습(훈련) 데이터 세트
iris_train = iris_n[random_sample == 1, 1:4]
# 학습(훈련) 데이터 세트
iris_train = iris[random_sample == 1, 1:4]
iris_train
# 트레이닝 라벨
iris_lable = iris[random_sample == 1, 5]
# 테스트 데이터 세트
iris_test = iris[random_sample == 2, 1:4]
# 트레이닝 라벨
iris_train_lable = iris[random_sample == 1, 5]
# 테스팅 라벨
iris_test_lable = iris[random_sample == 2, 5]
rm(list=ls())
# 실습) iris 종 판별하기 ===================================================================================
iris = read.csv("data/Iris.csv")
str(iris)
# 각 species 수 & 비율 확인
table(iris$Species)
prop.table(table(iris$Species))
# 정규화
normalize = function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# 마지막 4번째 컬럼은 '종'이므로 정규화에서 제거
iris_n = as.data.frame(lapply(iris[1:3], normalize))
#결과 확인
summary(iris_n)
# 마지막 4번째 컬럼은 '종'이므로 정규화에서 제거
iris_n = as.data.frame(lapply(iris[1:4], normalize))
#결과 확인
summary(iris_n)
# 마지막 4번째 컬럼은 '종'이므로 정규화에서 제거
iris_n = as.data.frame(lapply(iris[1:5], normalize))
#결과 확인
summary(iris_n)
# 랜덤 위한 시드값 생성
set.seed(1234)
# 75 : 25의 비율로 데이터 나눔
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25))
str(random_sample)
summary(random_sample)
random_sample
# 학습(훈련) 데이터 세트
iris_train = iris[random_sample == 1, 1:4]
iris_train
# 트레이닝 라벨
iris_train_lable = iris[random_sample == 1, 5]
# 테스트 데이터 세트
iris_test = iris[random_sample == 2, 1:4]
iris_test
rm(list=ls())
# 실습) iris 종 판별하기 ===================================================================================
iris = read.csv("data/Iris.csv")
str(iris)
# 첫 번쨰 컬럼인 id 삭제
iris = iris[-1]
str(iris)
# 정규화
normalize = function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# 마지막 5번째 컬럼은 '종'이므로 정규화에서 제거
iris_n = as.data.frame(lapply(iris[1:4], normalize))
#결과 확인
summary(iris_n)
iris_n
# 랜덤 위한 시드값 생성
set.seed(1234)
# 75 : 25의 비율로 데이터 나눔
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25))
random_sample
# 학습(훈련) 데이터 세트
iris_train = iris[random_sample == 1, 1:4]
iris_train
# 트레이닝 라벨
iris_train_lable = iris[random_sample == 1, 5]
iris_train_lable
# 테스트 데이터 세트
iris_test = iris[random_sample == 2, 1:4]
iris_test
# 테스팅 라벨
iris_test_lable = iris[random_sample == 2, 5]
iris_test_lable
# k-nn 알고리즘 라이브러리 세팅
library(class)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 3)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_lable,
k = 3)
CrossTable(wbcd_test_label, predict, prop.chisq = F)
rm(list=ls())
# 실습) iris 종 판별하기 ===================================================================================
iris = read.csv("data/Iris.csv")
str(iris)
# 첫 번쨰 컬럼인 id 삭제
iris = iris[-1]
str(iris)
# 각 species 수 & 비율 확인
table(iris$Species)
prop.table(table(iris$Species))
# 정규화
normalize = function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# 마지막 5번째 컬럼은 '종'이므로 정규화에서 제거
iris_n = as.data.frame(lapply(iris[1:4], normalize))
#결과 확인
summary(iris_n)
iris_n
# 랜덤 위한 시드값 생성
set.seed(1234)
# 75 : 25의 비율로 데이터 나눔
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25))
random_sample
# 학습(훈련) 데이터 세트
iris_train = iris[random_sample == 1, 1:4]
iris_train
# 트레이닝 라벨
iris_train_lable = iris[random_sample == 1, 5]
rm(list=ls())
# 실습) iris 종 판별하기 ===================================================================================
iris = read.csv("data/Iris.csv")
str(iris)
# 첫 번쨰 컬럼인 id 삭제
iris = iris[-1]
str(iris)
# 각 species 수 & 비율 확인
table(iris$Species)
prop.table(table(iris$Species))
# 정규화
normalize = function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# 마지막 5번째 컬럼은 '종'이므로 정규화에서 제거
iris_n = as.data.frame(lapply(iris[1:4], normalize))
#결과 확인
summary(iris_n)
iris_n
# 랜덤 위한 시드값 생성
set.seed(1234)
# 75 : 25의 비율로 데이터 나눔
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25))
random_sample
# 학습(훈련) 데이터 세트
iris_train = iris[random_sample == 1, 1:4]
iris_train
# 트레이닝 라벨
iris_train_label = iris[random_sample == 1, 5]
iris_train_label
# 테스트 데이터 세트
iris_test = iris[random_sample == 2, 1:4]
iris_test
# 테스팅 라벨
iris_test_label = iris[random_sample == 2, 5]
iris_test_label
# k-nn 알고리즘 라이브러리 세팅
library(class)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 3)
CrossTable(iris_test_label, predict, prop.chisq = F)
source('C:/dev/lab-R/ML/ml01_kNN알고리즘.R', encoding = 'UTF-8')
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 10)
CrossTable(iris_test_label, predict, prop.chisq = F)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 3)
CrossTable(iris_test_label, predict, prop.chisq = F)
# 75 : 25의 비율로 데이터 나눔
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.7, 0.3))
# 학습(훈련) 데이터 세트
iris_train = iris[random_sample == 1, 1:4]
# 트레이닝 라벨
iris_train_label = iris[random_sample == 1, 5]
# 테스트 데이터 세트
iris_test = iris[random_sample == 2, 1:4]
# 테스팅 라벨
iris_test_label = iris[random_sample == 2, 5]
# k-nn 알고리즘 라이브러리 세팅
library(class)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 3)
CrossTable(iris_test_label, predict, prop.chisq = F)
# 표준화
iris_z = as.data.frame(scale(iris[-1]))
# 표준화
iris_z = as.data.frame(scale(iris[2:5]))
# 표준화
iris_z = as.data.frame(scale(iris[-1]))
# 표준화
iris_z = as.data.frame(scale(iris[]))
# 표준화
iris_z = as.data.frame(scale(iris))
# 표준화
iris_z = as.data.frame(scale(iris[-1]))
# 표준화
iris_z = as.data.frame(scale(iris[2:5]))
# 표준화
iris_z = as.data.frame(scale(iris[2:5, ]))
# 표준화
iris_z = as.data.frame(scale(iris[1:5, ]))
# 75 : 25의 비율로 데이터 나눔
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25))
random_sample
# 학습(훈련) 데이터 세트
iris_train = iris[random_sample == 1, 1:4]
iris_train
# 트레이닝 라벨
iris_train_label = iris[random_sample == 1, 5]
iris_train_label
# 테스트 데이터 세트
iris_test = iris[random_sample == 2, 1:4]
iris_test
# 테스팅 라벨
iris_test_label = iris[random_sample == 2, 5]
iris_test_label
# k-nn 알고리즘 라이브러리 세팅
library(class)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 3)
CrossTable(iris_test_label, predict, prop.chisq = F)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 3)
CrossTable(iris_test_label, predict, prop.chisq = F)
iris_n
# 75 : 25의 비율로 데이터 나눔
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25))
# 학습(훈련) 데이터 세트
iris_train = iris[random_sample == 1, 1:4]
# 트레이닝 라벨
iris_train_label = iris[random_sample == 1, 5]
# 테스트 데이터 세트
iris_test = iris[random_sample == 2, 1:4]
# 테스팅 라벨
iris_test_label = iris[random_sample == 2, 5]
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 3)
CrossTable(iris_test_label, predict, prop.chisq = F)
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25))
random_sample
# 학습(훈련) 데이터 세트
iris_train = iris[random_sample == 1, 1:4]
iris_train
# 트레이닝 라벨
iris_train_label = iris[random_sample == 1, 5]
iris_train_label
# 테스트 데이터 세트
iris_test = iris[random_sample == 2, 1:4]
iris_test
# 테스팅 라벨
iris_test_label = iris[random_sample == 2, 5]
iris_test_label
# k-nn 알고리즘 라이브러리 세팅
library(class)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 3)
CrossTable(iris_test_label, predict, prop.chisq = F)
# 랜덤 위한 시드값 생성
set.seed(1234)
# 75 : 25의 비율로 데이터 나눔
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25))
# 학습(훈련) 데이터 세트
iris_train = iris[random_sample == 1, 1:4]
# 트레이닝 라벨
iris_train_label = iris[random_sample == 1, 5]
# 테스트 데이터 세트
iris_test = iris[random_sample == 2, 1:4]
# 테스팅 라벨
iris_test_label = iris[random_sample == 2, 5]
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 3)
CrossTable(iris_test_label, predict, prop.chisq = F)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 3)
CrossTable(iris_test_label, predict, prop.chisq = F)
# 랜덤 위한 시드값 생성
set.seed(1234)
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25))
random_sample
# 학습(훈련) 데이터 세트
iris_train = iris[random_sample == 1, 1:4]
iris_train
# 트레이닝 라벨
iris_train_label = iris[random_sample == 1, 5]
iris_train_label
# 테스트 데이터 세트
iris_test = iris[random_sample == 2, 1:4]
iris_test
# 테스팅 라벨
iris_test_label = iris[random_sample == 2, 5]
iris_test_label
# k-nn 알고리즘 라이브러리 세팅
library(class)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 3)
CrossTable(iris_test_label, predict, prop.chisq = F)
random_sample
# 랜덤 위한 시드값 생성
set.seed(1234)
# 랜덤 위한 시드값 생성
set.seed(2345)
# 75 : 25의 비율로 데이터 나눔
random_sample = sample(2, nrow(iris_n), replace = TRUE, prob = c(0.75, 0.25))
# 학습(훈련) 데이터 세트
iris_train = iris[random_sample == 1, 1:4]
# 트레이닝 라벨
iris_train_label = iris[random_sample == 1, 5]
# 테스트 데이터 세트
iris_test = iris[random_sample == 2, 1:4]
# 테스팅 라벨
iris_test_label = iris[random_sample == 2, 5]
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 3)
CrossTable(iris_test_label, predict, prop.chisq = F)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 10)
CrossTable(iris_test_label, predict, prop.chisq = F)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 12)
CrossTable(iris_test_label, predict, prop.chisq = F)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 13)
CrossTable(iris_test_label, predict, prop.chisq = F)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 8)
CrossTable(iris_test_label, predict, prop.chisq = F)
# k-nn 알고리즘 실행
predict = knn(train = iris_train,
test = iris_test,
cl = iris_train_label,
k = 5)
CrossTable(iris_test_label, predict, prop.chisq = F)
